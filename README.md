
## やりたいこと

データ変換のフレームワーク（データ変換の集合体）。

データ変換・送出機能を組み合わせて、
 - 複数の外部システムから定期的にデータを拾ってきて、それぞれの定義でデータ変換して（フィルタをかけて）、ElasticSearchとRDBに投げつける、とか
 -  オレオレLogstash的なもの、とか
 - ダッシュボード的なレポートを定期的に出力する、とか
 
をプログラミングなしで（テンプレートファイルだけを書き換えて）できるようになる

## デモ
sbtのインストールされているマシンで、 `sbt run` すると、デモ（minato.testApp.TestApp で設定された内容に基づくワークフロー）が起動する

デモでは、標準入力に（1行で）インプットされたJsonに対して、標準出力、標準エラー出力に定義された変換を行って出力を行う。

`{"name":"Taro","age":"20","favorite":"apple"}` の入力に対して、
 - 標準出力に `{"user-name":"Taro","age-of-user":"20"}`
 - 標準エラー出力に `set Taro:favorite apple` (Redisの登録クエリをイメージ)
を出力する。

データ変換部は主にテンプレートエンジンに担わせているので、入力は今のところJsonしか対応していないが、出力形式は何でも出力できる。
デモで用いている設定ファイルは以下の通り。minato.testApp.TestApp の当該部分を変更して再実行すれば、設定代えて実行できる。

```
{
	"Departures": {
		"name" : "stdin",
		"source":{
			"type" : "stdin-json"
		},
		"destinations" : ["port1","port2"]
	},   
	"Ports" : {
		"name" : "port1",
		"mustache" : "{
		\"user-name\" : \"{{name}}\",
		\"age-of-user\" : \"{{age}}\"
		} ",
		"destinations" : ["terminal1"]
	},
	"Ports" : {
		"name" : "port2",
		"mustache" : "set {{name}}:favorite \"{{favorite}}\"",
		"destinations" : ["terminal2"]
	} ,
	"Terminals" : {
		"name" : "terminal1",
		"anchor" : {
			"type" : "stdout"
		}
	},
	"Terminals" : {
		"name" : "terminal2",
		"anchor" : {
			"type" : "stderr"
		}
	}
}
```


## データ変換部分の構成要素と、それぞれによって何ができるか

 - Itinerary 全体のワークフロー定義 実装済み
   Itinerary は Departure(始点), Port(中継点), Terminal(終点) それぞれ0個以上の集合からなる。
    - 主な役割: ワークフローのバリデーションや、ワークフローの起動を行う。
    - ワークフローはDAGであるよう制約をつけている
   
 - Departure (始点)
    データを外部から取得したり、生成したりして、そのデータをPortやTerminalに送る機能を持つ。
    ただ1つのSourceと、1個以上のDestination(PortあるいはTerminal)への参照を持つ
     
    - Source
    データを取得したり、生成したりする。
       -  標準入力からJsonでデータを生成する ← 実装済み
       -  httpで通信を受け付ける機能 ← 未実装
       -  httpでどこかに情報をリクエストして取ってくる機能 ← 未実装
    
 - Port (中継点)
    データを変換したり、分解したり、くっつけたり、振り分けたりする機能を持つ
```
      Port 1-1+ Manifest 1-(0..1) Transshipment
                       1-1 unloader 1-(0..1) filter
                                    1-* unpacker
                                    1-* decorator
                       1-1 warehouse
                       1-* consignee 1-(0..1) filter
                                     1-1 accumulator
                                     1-1+ destination
```

     - Manifest … 変換・転送規則の集合
     - Transshipment … 直接データを変換する（外部問い合わせなどで、URLからリクエスト結果を取得するなどを想定）←未実装
     - unloader … Portが受け取ったデータを異なる粒度に分解したりする（例えば検索結果一覧から、レコード単位のデータに変換するなどの役割を持つ） ← 機能は実装済みだが、設定ファイルのパーサが未実装
     - filter … 条件に従って、条件にそぐわないデータは変換から除外する　←　機能は実装済みだが、設定ファイルのパーサが未実装
     - unpacker … 条件に従ってデータを分解する ←　機能は実装済みだが設定ファイルのパーサが未実装
     - decorator … 分解したデータに付加情報をつける（例えばレコード単位に分解したデータに、取得時刻をつけたい場合など） ←　機能は実装済みだが設定ファイルのパーサが未実装
     - warehouse … データを蓄えて塊を作る（例えばレコードを10件ずつにまとめてレポートを作成する場合など）← 未実装
     - consignee … warehouseが吐き出したデータを変換して次の処理に回す
     - accumulator … データを変換する（内部形式のオブジェクトで持っているデータを、テンプレートエンジンなどに当てて、JSONなどの形式に変換する） ← テンプレートエンジン(mustache)での変換のみ実装済み
     - destination … 次のPortやTerminalへの参照。accumulatorで生成したJsonなりのデータを持って、次のPort,Terminalをキックする
    
 - Terminal (終点)
    データを出力する。ただ一つのTerminalAnchorを持つ
    - TerminalAnchor  …  データを出力する
     　- 標準出力に表示する ← 実装済み
       - 標準エラー出力に表示する ← 実装済み
       - 文字列をURLとして解釈してリクエストする ← 未実装
       - HTTPでデータをPOSTする ← 未実装
       - SQL,NoSQLなどにクエリを投げる ← 未実装
       - ファイルを出力する ← 未実装


## アプリケーションとして持つ機能
 - 設定ファイルを読み込んで、ワークフローを起動する機能 ← 実装済み、ただし設定ファイルのパーサが殆どかけていない
 - 設定ファイルを基に、環境に最適化されたJarなりなんなりを生成する機能 ← 未実装。このJarをAWSのLambdaやAzureのFunctionに持っていていい感じになるようにしたい
 
 - 設定ファイルのエディタ - 設定ファイルを簡単に作れるようにしたい　←　未実装
 - 設定ファイルのシミュレータ - ブラウザ上で各種設定やテンプレートを変えると、瞬時に出力が変わるみたいな、高速でトライアンドエラーして、設定できる機能が欲しい　←　未実装

 - あと処理効率的には割と無駄があるので、たくさんのデータを処理するとかには現時点であまり向いていない気がする

## 検討事項
使い勝手として、一番肝心なところは
- 設定ファイルが超簡便にかけて、直感的に、超高速で実装できる

ところだと思っていて、
- 設定ファイルはどんな感じがベストか
- 変換部分はテンプレート（のみ）でよいか

などは検討が必要
